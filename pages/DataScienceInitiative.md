## Oklahoma Data Science Initiative

**Project description:** Part of Oklahoma's State Data Platform (SDP) longevity support and services is to provide state agencies with advanced data analytics, machine learning capabilities, and program-driven classification and prediction models. As we develop and grow the foundational data discovery and data storage centralization through our hub-and-spoke model, we also will define the expectations for machine learning and AI model support. This Data Science (DS) Initiative involves creating a dedicated Data Science team, creating a Data Science Lifecycle and MLOps strategy, procuring necessary Data Science tools, and defining minimum agency guidelines for model creation. 


### 1. Building a Data Science team
Although the entire project encompasses building out a Data Science team, the first step of the process is defining the personnel who can provide the necessary skillset of Data Science services and defining the expectation for progression of skills as the team grows. The Data Science team is built of Data Analysts and Data Scientists; however, the responsibilities and workload between the two roles are not exclusive. Common responsibilities in the early stages of the team center around Data Discovery as discovering existing datasets within state agencies is pivotal to the success of the SDP and Data Science team. Once datasets have been identified and schemas verified, the next step is working with the respective agency and the Data Engineering team to create a pipeling for data migration into the Google Cloud Platform (GCP). Once data has been properly stored and tagged, the data science team will also assist with descriptive statistics, Exploratory Data Analysis (EDA), and standard visualization and basic analytics. Data Scientists will be given more hands-on work with further Advanced Data Analytics (ADTA) and model creation. It is important as well to provide a path for advancement within the team and organization. A Data Analyst can progress towards a Sr. Data Analyst or Data Scientist postion and a Data Scientist can progress to Sr. Data Scientist or Sr. Technical Advisor. Both paths of progression can support future growth into managerial positions.

### 2. Creating a Data Science Lifecycle and MLOps Strategy
Where every step in the DS Initiative is important, creating and standardizing a DS Lifecycle and MLOps Strategy is vital to the longevity of the DS team and the models deployed for state agencies. This is argueably the most complex stes of the project as there is no true national standard for a DS Lifecycle or MLOps Strategy. The most crucial piece of this step is defining the lifecycle and strategy early on to relay expectations of data quality and data governance from the point of data entry to its final destination. Where a DS Lifecycle and MLOps Strategy can often be considered the same, the separation here is that the DS Lifecycle starts from defining the business problem/quesiton to model deployment and is an extension of the organization's Data Lifecycle. MLOps is focused more directly on design, development, deployment, and operations of the model and helps maintain, sustain, and accelerate value <ins>after development</ins>. For more detail into existing DS Lifecycle and MLOps Strategy, please use the following links (information in links are subject to continuous change):

State of Oklahoma Data Science Lifecycle: <br>
State of Oklahoma MLOps Strategy:

### 3. Assist with Data ETL Pipeline creation, Metadata tagging, and Database management.
Once an agency has become familiar with their GCP environment, designing and deploying pipelines for the data becomes paramount. Most agencies currently lack centralized databases and piping data from various locations is common. Working with the Data Engineering team, we determine where the location of specific datasets reside and determine the best resource for moving data. One of the most common methods utilized is GCP's Data Cloud Fusion which allows code-free ETL deployment and end-to-end data lineage for risk analysis and future troubleshooting. This is often the preferred method as most state agencies will take over pipeline management and often do not have the Python or Bash skills to troubleshoot a pipeline issue.
<br><br>
Once the data has reached GCP, the next step is to have it 'pass' through Google's Dataplex for Metadata tagging. This allows for additional security for certain data deemed confidential. Dataplex allows for centralized security and policy governance even if an agency independently does not assign a sensitivity tag to a particular variable or field themselves. Dataplex also utilizes Google's built-in AI and Machine Learning capabilities to automate classification, data quality, and data discovery across the hub-and-spoke model. Dataplex is a key asset of the State Data Platform as it provides that extra layer of security that cannot be achieved in local agency-owned databases.
<br><br>
Once the data has been properly tagged, it is placed into an agency's GCP BigQuery. BigQuery is GCP's serverless data warehouse with built-in machine learning and business insight capabilities. Once data has been loaded into an agency's BigQuery, an agency can manage, query, and transform data to use for analytics across the different datasets from various departments within the agency. 

### 4. Register datasets in the DASH application
Once data has been migrated from a siloed, localized location within a state agency to their GCP spoke, the next step is for the Data Owner to register the agency-selected datasets for the DASH application. Once a dataset is registered, other state agencies may request access to the data through DASH which requires approval from the respective Data Owner. DASH is the State of Oklahoma Data Sharing Hub. This hub is curated by OMES; however, the registered datasets are maintained and governed by the state agency's Data Owner who registered the dataset. This acts as both a sharing hub as well as an additional form of security when sharing data between agencies. Ultimately, the respective agency's Data Owner may control who sees the data, for how long, and may pull access to the dataset at any point.

For more details see: [Oklahoma Data-Driven Services](https://oklahoma.gov/omes/services/information-services/dataservices.html).
<br>
For up-to-date announcements see: [Oklahoma Data-Driven Service Announcements](https://oklahoma.gov/omes/services/information-services/dataservices/announcements.html).
<br>
Google's Case Study on the State of Oklahoma's State Data Platform: [Google Case Study](https://cloud.google.com/customers/state-of-oklahoma-omes).
